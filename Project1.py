# -*- coding: utf-8 -*-
"""DL!.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-IpMrs-RMM1jhlPyHyrb-kz6wGNIvrfo
"""

import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping

questions = pd.read_csv(r'/content/Questions.csv', encoding='ISO-8859-1', on_bad_lines='skip', engine='python')
answers = pd.read_csv(r'/content/Answers.csv', encoding='ISO-8859-1')
tags = pd.read_csv(r'/content/Tags.csv', encoding='ISO-8859-1')

print("Questions shape:", questions.shape)
print("Tags shape:", tags.shape)

questions.head()

tags.head()

questions.info()
questions.isnull().sum()

answers.info()
answers.isnull().sum()

print(answers.isnull().sum())

tags.info()
tags.isnull().sum()

top_tags = tags['Tag'].value_counts().head(10)
top_tags

import matplotlib.pyplot as plt

top_tags.plot(kind='bar', figsize=(8,4), title='Top 10 Most Common Tags')
plt.xlabel('Tag')
plt.ylabel('Count')
plt.show()

questions['Score'].describe()

questions['Score'].hist(bins=50, figsize=(8,4))
plt.title('Score Distribution')
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.show()

questions['TitleLength'] = questions['Title'].apply(lambda x: len(str(x).split()))
questions['BodyLength'] = questions['Body'].apply(lambda x: len(str(x).split()))

questions[['TitleLength', 'BodyLength']].describe()

questions['BodyLength'].hist(bins=50, figsize=(8,4))
plt.title('Body Length Distribution')
plt.xlabel('Word Count')
plt.ylabel('Number of Questions')
plt.show()

tags_per_q = tags.groupby('Id').size()
tags_per_q.describe()

from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning
import warnings

warnings.filterwarnings("ignore", category=MarkupResemblesLocatorWarning)


def clean_html(raw_html):
    clean_text = BeautifulSoup(raw_html, "html.parser").get_text()
    clean_text = re.sub(r'\s+', ' ', clean_text)
    return clean_text.strip().lower()

# Clean question body and title
questions['CleanTitle'] = questions['Title'].apply(clean_html)
questions['CleanBody'] = questions['Body'].apply(clean_html)

# Optionally clean answers
answers['CleanBody'] = answers['Body'].apply(clean_html)

# Remove missing tags
tags = tags.dropna(subset=['Tag'])

top_tags = tags['Tag'].value_counts().head(10).index.tolist()

tags_top = tags[tags['Tag'].isin(top_tags)]
q_tag_map = tags_top.groupby('Id')['Tag'].apply(list).reset_index()

data = pd.merge(questions, q_tag_map, how='inner', on='Id')

answers_grouped = answers.groupby('ParentId')['Body'].apply(lambda x: ' '.join(x)).reset_index()
data = pd.merge(data, answers_grouped, how='left', left_on='Id', right_on='ParentId')

data['text'] = (data['Title'].fillna('') + ' ' +
                data['Body_x'].fillna('') + ' ' +
                data['Body_y'].fillna(''))

mlb = MultiLabelBinarizer()
Y = mlb.fit_transform(data['Tag'])

max_words = 20000
max_len = 200

tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(data['text'])
X_seq = tokenizer.texts_to_sequences(data['text'])
X_pad = pad_sequences(X_seq, maxlen=max_len, padding='post', truncating='post')

X_train, X_val, Y_train, Y_val = train_test_split(X_pad, Y, test_size=0.2, random_state=42)

model = Sequential([
    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),
    LSTM(128, return_sequences=False),
    Dense(64, activation='relu'),
    Dense(len(top_tags), activation='sigmoid')  # multilabel sigmoid
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
model.fit(X_train, Y_train,
          validation_data=(X_val, Y_val),
          epochs=10, batch_size=128,
          callbacks=[early_stop])

sample_idx = 0
pred = model.predict(X_val[sample_idx:sample_idx+1])
pred_tags = mlb.inverse_transform((pred > 0.5).astype(int))
print("Predicted tags:", pred_tags)
print("True tags:", mlb.inverse_transform(Y_val[sample_idx].reshape(1, -1)))

print(pred.shape)  # Should be (N, 10)

pred_labels = (pred > 0.5).astype(int)
print("Example predictions (binary tags):")
print(pred_labels[:5])

from sklearn.metrics import f1_score, precision_score, recall_score

# Calculate predictions for the entire validation set
pred = model.predict(X_val)
# Flatten to compute metrics
pred_labels = (pred > 0.5).astype(int)

f1 = f1_score(Y_val, pred_labels, average='micro')
precision = precision_score(Y_val, pred_labels, average='micro')
recall = recall_score(Y_val, pred_labels, average='micro')

print(f"F1 Score (micro): {f1:.4f}")
print(f"Precision (micro): {precision:.4f}")
print(f"Recall (micro): {recall:.4f}")